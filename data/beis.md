BEIS Monitoring and Evaluation Framework

BEIS Research Paper Number 2020/016

December 2020

© Crown copyright 2020


This publication is licensed under the terms of the Open Government Licence v3.0 except where otherwise stated.
To view this licence, visit nationalarchives.gov.uk/doc/open-government-licence/version/3 or write to the
Information Policy Team, The National Archives, Kew, London TW9 4DU, or email:
psi@nationalarchives.gsi.gov.uk.


Where we have identified any third-party copyright information you will need to obtain permission from the
copyright holders concerned.


Any enquiries regarding this publication should be sent to us at:
enquiries@beis.gov.uk

# Contents

Foreword from the Permanent Secretary - 4

Executive Summary - 5

Introduction - 7

- 1.1 BEIS’ vision for monitoring and evaluation - 7

Monitoring and evaluation in BEIS - 9

- 2.1 Why does BEIS monitor policies? - 9
- 2.2 Why does BEIS evaluate policies? - 10
- 2.2.1 Types of evaluation used in BEIS - 11

Standards for monitoring and evaluation in BEIS - 12

- 3.1 Where do monitoring and evaluation fit into policy design? - 13
- 3.2 Monitoring and evaluation planning - 14
- 3.2.1 Monitoring and evaluation planning for BEIS investments - 14
- 3.2.2 Monitoring and evaluation planning for statutory commitments to review regulations - 15
- 3.2.3 Checklist for policy makers: required monitoring and evaluation planning - 15

Achieving the BEIS monitoring and evaluation vision - 31

- 4.1 Establish comprehensive monitoring and evaluation coverage - 31
- 4.1.1 Requiring monitoring and evaluation plans - 31
- 4.1.2 Encouraging best practice in our partner organisations - 31
- 4.2 Embed monitoring and evaluation into governance processes - 32
- 4.2.1 Evaluation governance - 32
- 4.2.2 Investment governance - 33
- 4.2.3 Regulatory governance - 34
- 4.3 Build policy and analytical capacity and capability - 35
- 4.4 Facilitate a positive learning culture - 36
- 4.5 Maintain independent, transparent quality assurance of findings - 36

Next steps - 37

Appendices - 38

- A1. Glossary of terms - 39
- A2. BEIS evaluation case studies - 43
- A3. Theory of Change template - 49
- A4. Logical framework (logframe) template - 51
- A5. Further information on additional data requirements and linking - 52
- A6. Regulatory post implementation review plan template - 54

# BEIS Monitoring and Evaluation Framework

Foreword from the Permanent Secretary

I am pleased to introduce the Department for Business, Energy & Industrial Strategy (BEIS) Monitoring and Evaluation Framework.

BEIS is at the heart of the government’s commitment to build an economy that works for everyone, with great places across the UK for people to work and for businesses to invest, innovate and grow. The Department promotes investment in science, research and innovation to ensure the UK is the most innovative economy, builds long-term strategic partnerships with business to drive increased productivity across all the sectors, works to improve awareness of and access to finance for small and medium enterprises (SMEs) and high growth, innovative-based businesses, promotes competitive markets and responsible business practices, aims to ensure the UK has a reliable, low cost and clean energy system, and promotes global action to tackle climate change. BEIS encourages the utilisation of the best technology to achieve these ambitions.

The development of effective programmes to progress departmental policies depends on timely and accurate monitoring and evaluation to understand and assess progress against objectives, understand what works for whom, how and why, and whether it is value for money. Without continuous monitoring and evaluation, it is not possible to understand how far policies are achieving their goals, nor generate the evidence needed to develop the most effective policies in the future.

This Framework reflects our strong commitment to maintaining and developing a robust evidence base across BEIS and its partner organisations, providing a clear pathway to embedding monitoring and evaluation throughout the policy cycle.

We will continue a coherent and comprehensive programme of work to ensure full monitoring and evaluation (M&E) coverage of our key policies and programmes, M&E is firmly embedded in our governance processes, we continue to build policy, project delivery and analytical capacity and capability, facilitate a positive learning culture and maintain an independent external expert peer review system to quality assure our evaluations.

My warm thanks to everyone in the department who has contributed to the development of this important Framework.

# BEIS Monitoring and Evaluation Framework

# Executive Summary

BEIS currently spends around £14bn a year on a range of policy areas including science and innovation, business and enterprise, energy, and clean growth. It also regulates several areas including labour markets, consumer markets and business law.

The department is accountable for how it spends taxpayers’ money and the financial burden its regulation places on organisations across the UK. To meet its priorities BEIS is strongly committed to using robust evidence to support development, implementation, and improvement of our policies.

This Framework outlines BEIS’ vision for comprehensive, proportionate, good quality monitoring and evaluation across the department and its partner organisations.

BEIS has benefitted from learning through process evaluations, which assess how the policy is being or has been delivered and whether improvements can be made; impact evaluations, which assess what difference the policy has made and why; and value for money evaluations, which assess the policy by comparing the (monetised) benefits of the policy with its costs (cost-benefit analysis) or compare the relative costs and outcomes (effects) of different courses of action (cost-effectiveness analysis). To fully understand a policy’s delivery, effect, and value for money all types of evaluation are typically employed.

BEIS expects policy teams to:

1. demonstrate during policy design that learning from previous monitoring and evaluation has been addressed;
2. clarify the policy objectives and anticipated effects in a Theory of Change;
3. assess what level of monitoring and evaluation is proportionate;
4. assess what evaluation evidence is needed, who will use it, and when it will be required;
5. identify evaluation objectives and questions;
6. identify the evaluation approach and methodologies required;
7. identify monitoring and evaluation data requirements;
8. secure the internal resources and budget required;
9. conduct or commission the evaluation;
10. use and publish the findings.

To achieve the BEIS monitoring and evaluation vision central analysis will seek to:

- Establish comprehensive, appropriate and proportionate monitoring and evaluation coverage across all policies and programmes in BEIS and its partner organisations.
- Firmly embed monitoring and evaluation into structures and governance processes to ensure that proportionate monitoring and evaluation is delivered, even in challenging circumstances.
- Build capacity and capability in the policy, project delivery and analytical professions to conduct and commission good quality monitoring and evaluation.
- Facilitate a positive learning culture across BEIS where lessons from monitoring and evaluation inform policy decisions and delivery, and future monitoring and evaluation design.

1 BEIS annual report and accounts 2019 to 2020: BEIS Annual Report and Accounts 2019 to 2020

BEIS Monitoring and Evaluation Framework

•   Maintain independent and transparent quality assurance of evaluation findings, so pat stakeholders can have confidence in pe findings generated from monitoring and evaluation of BEIS policies. This Framework outlines how pis will be achieved.

# BEIS Monitoring and Evaluation Framework

Introduction

BEIS was created in July 2016 and is at the heart of the government’s commitment to build an economy that works for everyone, with great places across the UK for people to work and for businesses to invest, innovate and grow. The department currently spends around £14bn a year on a range of policy areas including science and innovation, business and enterprise, and energy and clean growth. It also regulates several areas including labour markets, consumer markets and business law.

The department needs to be accountable for how it spends taxpayers’ money and the financial burden its regulation places on organisations across the UK. In a recent report on business support schemes the National Audit Office lists monitoring and evaluation plans amongst recommendations for implementation from March 2020. Additionally, BEIS put in place the Government’s response to the COVID-19 crisis, and the government has continued to support the economy approving over £65bn in support, for which a proportionate assurance regime will be implemented.

To meet its priorities, BEIS is strongly committed to using robust evidence to support the development, implementation, and improvement of BEIS policies. Proportionate monitoring and evaluation facilitate the development of the most effective interventions by helping to understand how BEIS policies, projects and regulations are being implemented, what effects they have, for whom, how, why, and in what circumstances. This Framework builds on the 2010 and 2014 evaluation strategies published by the Department for Business, Innovation & Skills (BIS) and the building of an evaluation function with a strong emphasis on learning in the Department of Energy and Climate Change (DECC). It outlines BEIS’ vision for proportionate, good quality monitoring and evaluation of interventions across the department and its partner organisations that informs policy design, development and implementation, and legislative options.

HM Treasury has published two books that provide guidance on how to undertake monitoring and evaluation, which this Framework builds on. The Green Book provides guidance on how to appraise and evaluate policies, while the Magenta Book provides guidance on what to consider when designing an evaluation.

# 1.1 BEIS’ vision for monitoring and evaluation

BEIS' vision is to create the conditions which will allow proportionate, good quality monitoring and evaluation to be consistently used across the department. To achieve departmental

BEIS annual report and accounts 2019 to 2020: Link

nao.org.uk/report/business-support-schemes/

Link

Link

Link

Link

Link

# BEIS Monitoring and Evaluation Framework

Objectives, monitoring, and evaluation must also be used to inform and influence key policy decisions and delivery.

To achieve our vision, BEIS aim to:

Establish comprehensive, appropriate and proportionate monitoring and evaluation coverage across all policies and programmes in BEIS and its partner organisations.
Firmly embed monitoring and evaluation into governance processes to ensure pat proportionate monitoring and evaluation is delivered, even in challenging circumstances.
Build capacity and capability in policy, project delivery and analytical professions to conduct and commission good quality monitoring and evaluation.
Facilitate a positive learning culture across BEIS where lessons from monitoring and evaluation inform policy decisions and delivery, and future monitoring and evaluation design.
Maintain independent and transparent quality assurance of evaluation findings, so pat stakeholders can have confidence in pe findings generated from monitoring and evaluation of BEIS policies.

Figure 1: Achieving the BEIS monitoring and evaluation vision

|Build policy and analytical capacity and capability|Build policy and analytical capacity and capability|
||
|Embed M&E into governance processes|Facilitate a positive learning culture|
|Establish comprehensive monitoring and evaluation coverage|Maintain an independent, transparent quality assurance of findings|

This Framework sets out how we will achieve this vision.

# BEIS Monitoring and Evaluation Framework

# 2. Monitoring and evaluation in BEIS

Monitoring and evaluation provide evidence to improve policies and inform decisions. This chapter summarises why BEIS monitors and evaluates policies and the approaches the department uses.

# 2.1 Why does BEIS monitor policies?

As it says in the Magenta Book, to be done well, both monitoring and evaluation should begin during the policy development with skilled expertise to ensure real-time evidence is available during implementation to aid decision-making. This can result in speedy changes to the policy design and objectives.

Monitoring data are collected throughout an intervention to provide answers to a number of policy, research and performance questions. This data typically covers all aspects of an intervention’s operation and is generally used to help track progress of an intervention’s delivery.

BEIS uses monitoring to:

- assess whether the policy has delivered the target outputs (such as numbers of units installed, or businesses signed up);
- demonstrate whether a policy is reaching its target population (by assessing the number and characteristics of people, organisations and businesses accessing or using a policy);
- identify data required to measure inputs, outputs, outcomes and impacts;
- understand stakeholders’ perceptions/attitudes towards the intervention/behaviour change;
- establish whether the intended outcomes have been achieved, and identify any unintended effects so senior managers can make informed decisions;
- link to public administrative, private and academic data (such as tax records, business databases or energy efficiency databases) to create richer data sets by collecting good quality identifiers;
- enable further research and evaluation by collecting contact details and characteristics of those affected by a policy and a similar comparison group who are not affected, before the intervention and after the anticipated impact, to assess that impact;
- inform cost-benefit analysis and determine whether assumptions about policy implementation, such as cost and time, were correct.

Further information on monitoring and evaluation design can be found in the Magenta Book (HM Treasury guidance on what to consider when designing an evaluation) and the Green Book (HM Treasury guidance on how to appraise and evaluate policies, programmes and projects).

https://www.gov.uk/government/publications/the-magenta-book

# BEIS Monitoring and Evaluation Framework

All BEIS policies and projects should develop proportionate good quality monitoring to assess and improve performance and inform learning, ahead of and throughout implementation. Further information on monitoring can be found in section ‘3.2.3.6 identify the appropriate monitoring approach’.

Frequent monitoring and evaluation outputs allow an assessment and explanation of progress towards realizing the intended benefits - benefits management. This enables corrective action to be taken where necessary. Benefits management is mandatory for all BEIS policies, it should be proportionate to the size and complexity of the policy.

Benefits management is a program management approach that aims to make sure the desired business change or policy outcomes have been clearly defined, are measurable and provide a compelling case for investment. Good benefits management, with input from key stakeholders and customers, will help:

- identify what you are aiming to achieve with the intervention;
- establish end goals – the desired positive outcomes and benefits from the intervention;
- set out a process to help monitor and track progress towards the end goals, so you know when you’ve achieved what you set out to deliver, as well as putting measures in place to mitigate risks and increase benefits;
- identify both the positive and negative effects from change.

As such benefits management provides valuable evidence and data to help in evaluating policies including whether they have delivered what was intended. Further guidance on effective benefits management is available from the Infrastructure and Projects Authority and other sources.

# Why does BEIS evaluate policies?

As it says in the Magenta Book “evaluation is the systematic assessment of the design, implementation and outcomes of an intervention”. Well designed and implemented evaluation provides an understanding of the actual economic, financial, social and environmental impacts of a policy; and/or provides an assessment of how it is/was implemented, why it did or did not deliver as expected, and whether it represents value for money.

This information can inform ongoing implementation decisions to maximize the impact of an intervention and can be fed into future development decisions.

Evaluation can inform thinking before, during and after intervention implementation. It can answer questions such as: What can we learn from previous monitoring and evaluation? How is the intervention being delivered? Are there any unintended consequences? What could be improved? What are the emerging impacts? What difference has it made for different groups? How has the context influenced delivery and intended outcomes? How much of the

Infrastructure and Projects Authority. (2017). Guide for Effective Benefits Management in Major Projects [pdf]. Crown Copyright. Available at: https://www.gov.uk/government/publications/guide-for-effective-benefits-management-in-major-projects [Accessed 5th November 2019]

Jenner, S. (2014) Managing Benefits. 2nd Edition. The Stationery Office.

The Magenta Book provides guidance on what to consider when designing an evaluation: https://www.gov.uk/government/publications/the-magenta-book

# BEIS Monitoring and Evaluation Framework

Impact can be attributed to the intervention? Can the intervention be expected to make a difference in other contexts? Is the intervention value for money?

There are two primary drivers of policy evaluation: learning and accountability. Learning helps manage risk and uncertainty of the policy and its implementation; provides an understanding of what works for whom, how, why, and in what circumstances; and informs policy development and ultimately decisions. Accountability relates to BEIS being transparent with its stakeholders, for example about how public money is spent (such as informing Spending Reviews, National Audit Office Reviews, and the requirements of the Better Regulation Executive and the Regulatory Policy Committee), how well an intervention is targeted, and whether a regulation has an appropriate balance between burden and protections.

# Types of evaluation used in BEIS

BEIS achieves learning and accountability through a combination of:

|Process evaluations|Impact evaluations|Value for Money evaluations|
||||
|Assess how the policy is being or has been delivered and whether improvements can be made. This is often through collecting and analysing stakeholder perceptions and administrative data.|Assess what changes have occurred, what difference the intervention has made and why. They answer questions such as: did it achieve its stated objectives? Who did the intervention affect? How did the effects vary across individuals, groups, sectors, geography, and time? What were the intended and unintended outcomes of the intervention? Can the change be attributed to the intervention? This is investigated through theory-based, experimental, and/or quasi-experimental approaches.|Assess the policy by comparing the (monetised) benefits of the policy with its costs (cost-benefit analysis) or compare the relative costs and outcomes (effects) of different courses of action (cost-effectiveness analysis). These approaches build on evidence gathered from impact evaluations and costs of the intervention. They answer the question: is the project or programme an economic, efficient, and effective use of resources?|

To fully understand an intervention’s implementation, effect, and value for money all types of evaluation are typically used in combination.

The exact research questions for each evaluation will be agreed at the start of the evaluation and reflect the needs of the intervention stakeholders, and the context in which it is implemented.

Further information on evaluation approaches used in BEIS can be found in appendix A2, including case studies.

See https://www.nao.org.uk/about-us/ for more information on the role of the National Audit Office.

# BEIS Monitoring and Evaluation Framework

Standards for monitoring and evaluation in BEIS

To maximise the potential for robust, useable findings that can inform policy implementation and decision-making, good quality monitoring and evaluation requires planning alongside policy design, linking monitoring and evaluation to policy objectives and evidence needs.

The checklist below summarises the standards required for policy makers.

|Figure 2: Monitoring and evaluation plan checklist for policy makers|
||
|1. Learning|Demonstrate learning from previous monitoring and evaluation has been addressed in the policy design|
|2. Theory of Change|Clarify the policy objectives and anticipated effects in a Theory of Change|
|3. Proportionality|Assess what level of monitoring and evaluation is proportionate|
|4. Evidence required|Assess what evaluation evidence is needed, who will use it, and when it will be required|
|5. Objectives and questions|Identify evaluation objectives and questions|
|6. Approach|Identify the evaluation approach required|
|7. Data requirements for monitoring and evaluation|Identify the data requirements|
|8. Resources|Secure the resources|
|9. Evaluation|Conduct / commission the evaluation|
|10. Use and publish findings|Use and publish the evaluation findings|

# BEIS Monitoring and Evaluation Framework

This chapter starts by outlining where monitoring and evaluation fit in the policy cycle. The checklist items are discussed in more detail in '3.2 Monitoring and evaluation planning' after a summary of what BEIS expects in monitoring and evaluation plans for BEIS investments and regulations.

# 3.1 Where do monitoring and evaluation fit into policy design?

Good monitoring and evaluation are built into the design of a policy and thought about throughout its development and implementation. This allows both the programme and the evaluation to be tailored to maximise the potential for robust, useable findings that can help future decision-making. The design of a policy will affect how rigorously it can be evaluated.

Failure to think about monitoring limits the ability to track progress, while failure to think about evaluation and build this into the policy design can preclude a reliable understanding of the impact of the policy being achieved; appropriate baseline data is often not collected and a comparison or control group is not available to help understand what would happen in the absence of the policy.

The Green Book presents a framework of how monitoring and evaluation fits into the policy development process. As it says in the Magenta Book monitoring and evaluation have a role at each stage in the policy cycle.

Figure 3: The policy cycle

|Rationale|Rationale: Why is government intervening? What is the problem that government is trying to solve? What does the evidence say about this problem?|
|||
|Objective|Feedback: What have we learnt? How will we use these results in future? Objective: What would success from the intervention look like? What metrics can we use to measure success?|
|Appraisal|Evaluation: Research and analysis answer the questions: Did the intervention work as expected? What was the impact on who and why? Was it cost-effective?|
|Monitoring|Appraisal: What are the options for intervening? What is the likely evidence on the effectiveness and cost-effectiveness of these options?|
|Feedback|Monitoring: Data collection to answer the questions: Did we do what we said we would do? How are our success metrics changing over time?|

Measurement of conditions prior to implementation of a project against which subsequent progress can be assessed, such as behaviors, attitudes, employment, turnover, emissions

HM Treasury guidance on how to appraise and evaluate policies, programs, and projects: The Green Book

HM Treasury guidance on what to consider when designing an evaluation: The Magenta Book

# BEIS Monitoring and Evaluation Framework

The outputs and learning from earlier evaluations feed into the rationale, objectives, and appraisal stages of the cycle.

# 3.2 Monitoring and evaluation planning

Monitoring and evaluation are most suitable for informing policy implementation and decisions when they have been planned alongside the development of the policy. This section discusses requirements for the monitoring and evaluation of BEIS investments and regulations, then discusses each item in the ‘monitoring and evaluation plan checklist for policy makers’ in turn.

# 3.2.1 Monitoring and evaluation planning for BEIS investments

The BEIS Projects and Investments Committee (PIC) scrutinises and approves significant, risky or contentious investments of taxpayer funds undertaken by the department.

PIC considers strategic, outline and full business cases in terms of: their strategic fit with ministerial priorities; the economic rationale for investing taxpayer funds according to the recommended option; assurance that expenditure is regular and proper and offers value for money; confirmation that the proposed expenditure is affordable; and confidence that the project is deliverable, considering timescale and the capability and capacity of those responsible. This aligns with the Treasury’s five-case methodology as set out in the Green Book, which includes a strategic, economic, commercial, financial, and management case.

A monitoring and evaluation plan is part of the management case. Figure 4 summarises what is required at each stage of a BEIS Project Investment Committee business case.

|Investment monitoring and evaluation planning requirements within BEIS|How previous M&E learning has informed project or policy development|
|||
|Strategic Business Case|A high-level outline of the purpose of the evaluation|
| |An articulation of the expected impacts and outcomes of the intervention|
| |An indication of the scale of the evaluation, and justification based on proportionality|
| |An initial estimate of budget and resources for M&E|
| |A discussion of the scope for piloting and testing prior to implementation|
|Outline Business Case|Above box plus: Theory of Change (a logic model plus a narrative of what is expected to happen)|
| |Reviewed by key stakeholders and signed off by the SRO/programme board|
| |The main monitoring and evaluation objectives|
| |The likely uses and users of the M&E evidence to assess the appropriateness of the M&E approach and timescales|
| |High level timetable setting out main stages of evaluation planning and delivery against the programme timetable, including BEIS Peer Review Group review(s)|
|Full Business Case|Above boxes plus: An initial set of evaluation questions|
| |Detail of monitoring and evaluation arrangements including delivery and reporting framework; including a log frame of key arrangements and partners|
| |Indication of any research required (type, scope, method of engagement)|
| |An initial data sources; milestones, targets and reporting plan|
| |The budget and resources allocated for M&E and evaluation expert|

With a whole life cost of £20m or above either to BEIS or the economy as a whole.

The Green Book - Appraisal and Evaluation in Central Government

# BEIS Monitoring and Evaluation Framework

The Performance and Risk Committee (P&R) provides assurance for the BEIS Executive
Committee and the Permanent Secretary on the performance and delivery of BEIS’
programme and policy commitments, as well as its Partner Organisations. It assesses
performance against agreed programme outcomes and milestones and provides assurance on
the operation of the BEIS monitoring and evaluation framework, including monitoring and
evaluation plans submitted to PIC as part of a business case.

Monitoring and evaluation planning for statutory commitments to review regulations

Departments and partner bodies are required to produce impact assessments (IAs) assessing
the costs and benefits of regulatory changes prior to consultation, enactment and
implementation. The evidence and analysis used within IAs are scrutinised by the independent
Regulatory Policy Committee (RPC).

Post implementation reviews (PIRs) of these regulatory changes are a key element of the
policy-making cycle and provide an evidence-based evaluation of the effectiveness of a
measure after it has been implemented and operational (after an appropriate period of time). A
PIR will review: the original policy objectives; the extent to which the measure is achieving its
intended effects/meeting its objectives; whether there have been any unintended
consequences; how well it is working; and the reasons why. It will also assess whether the
objectives could be achieved with a system that imposes less regulation.

Evidence from PIRs will support decisions about the next steps for a measure, which are:

- Renewal - measure continues without change
- Amendment - measure remains but changes are made to improve it
- Removal - measure is removed without replacement
- Replacement - measure is replaced or redesigned substantially

A summary of the monitoring and evaluation plan for the PIR is part of the IA template and
BEIS requires a more detailed PIR review plan to be completed for every high impact
statutory commitment to review. A PIR Plan template can be found in appendix A6. Analytical
guidance on conducting a PIR is provided as supplementary guidance to the Magenta Book.

Checklist for policy makers: required monitoring and evaluation planning

The remainder of this chapter takes the key aspects of monitoring and evaluation planning
from the checklist at Figure 2 and outlines what is expected in BEIS.

# BEIS Monitoring and Evaluation Framework

3.2.3.1 Demonstrate learning from previous monitoring and evaluation has been addressed in the policy design

As outlined in the ‘feedback’ stage of the policy cycle, policy development should not be conducted in isolation; learning from previous monitoring and evaluation and wider evidence should be built on. There should be some discussion of previous evidence, and how it has informed development of the intervention, and proposed monitoring and evaluation plans (in terms of key evidence gaps, for example) - or clarity that such evidence does not exist if it's a novel area.

3.2.3.2 Clarify the policy objectives and anticipated effects in a Theory of Change

As outlined in the Magenta Book (2.2.1), good policy making necessitates a thorough understanding of the intervention and how it is expected to achieve the expected outcomes, this also informs the monitoring and evaluation. The first thing to do is identify the objectives and anticipated outcomes and impacts of the policy. It is important to set this out clearly, to provide common understanding and framework for the evaluation plan and help identify exactly what the evaluation is assessing. The recommended way to do this is to set out the logic in a Theory of Change. For complex policies, it may be necessary to develop a series of linked Theories of Change (for more information on evaluating complexity see the Magenta Book supplementary guidance).

At an early stage of policy development, Theories of Change can be undertaken as a desk exercise, based on a review of policy documentation. However, developing and testing the theory with key stakeholders – for example organisations involved in the delivery and representatives of different groups affected by the intervention, will ensure all important issues are identified and assumptions are reality checked. The Theory of Change should be signed off by the Senior Responsible Officer and/or the project/programme board.

The benefits of a well-developed Theory of Change include:

- Improved policy development
- A shared vision of the intervention and end goals
- Enabling early thinking on how intervention success will be measured and understood
- A clear one page ‘story’ of the intervention
- Improving intervention delivery and management

Reference:

24 https://www.gov.uk/government/publications/the-magenta-book

25 ‘Handling Complexity in policy evaluation’: https://www.gov.uk/government/publications/the-magenta-book

# BEIS Monitoring and Evaluation Framework

Figure 5: Theory of Change

Context and rationale

How the policy links to BEIS objectives. The issue to be addressed, the context in which it is located, why the government should intervene

Policy objectives

How the policy is supposed to effect its various target outcomes

Outcomes

Outputs

The ultimate objectives of the policy, long term

Impacts

Specific short- and medium-term changes BEIS wants to achieve, related to the policy objectives, such as take up of energy efficiency measures, skills increases; new carbon technologies developed

The wider economic, financial; social or environmental effects and results, such as behavior change, jobs created, energy and greenhouse gas emission reductions, or increased productivity

Inputs

What resource is provided e.g.: grant funding; information

Assumptions, risks, mitigations

What factors and processes need to be in place to enable this progression?

Evaluation objectives

The focus of the systematic assessment

A well-developed Theory of Change should include:

- A summary of the context and rationale for intervention - how the intervention links to BEIS objectives and priorities, the issues being addressed, and the context within which intervention takes place.
- It should include the problem, its causes and its consequences, how the intervention will address the problem, and why the government should intervene (based on the existing knowledge base).
- It should summarize how the intervention aligns or overlaps with other similar interventions that may also affect the expected outcomes, and use these insights to help establish the boundaries around the intervention.
- SMART intervention objectives - how the intervention is supposed to affect its various target outcomes and what success would look like.

Creating a Theory of Change usually involves working backwards from impacts to inputs:

- Start with the expected impacts (the ultimate objectives of the intervention, the long-term economic, social and environmental outcomes such as reduced energy costs or change in employment attributed to the intervention).
- Then work backwards through the outcomes (what specific changes in attitudes, behaviors or skills BEIS wants to achieve – such as take up of energy efficiency measures; increased skills; new technologies developed), the outputs (what is expected to happen as a direct result of the proposed activities – such as the number of projects supported), and finally the expected policy inputs (resources provided such as grant funding, equipment and information).

The boxes in the diagram (containing inputs, outputs, outcomes and impacts) should be linked by arrows that represent causal relationships (the box at the end of the arrow is caused as a result of the box at the start of the arrow).

17

# BEIS Monitoring and Evaluation Framework

In addition to the summary of the context and rationale for intervention the accompanying narrative should include:

- The assumptions made about how these elements link together and enable the project to successfully progress from one element to the next (e.g. consumers are engaged/informed; firms are aware of and take up loans; investors can be identified; new technologies are used, etc.)
- Potential risks (businesses seek subsidies to raise returns on investments they would have made anyway, applicants don’t have the skills and resource to manage the delivery) and mitigating activities.
- Quality of evidence underlying the causal chains throughout, signposting where the weaker, riskier aspects of the Theory of Change are.
- Areas of uncertainty or interest on which the evaluation should focus.
- The evaluation objectives – the focus of the systematic assessment.

The Theory of Change should be updated regularly as the policy develops using the monitoring and evaluation evidence. A Theory of Change template can be found in appendix A3.

# Assess what level of monitoring and evaluation is proportionate

As outlined in the Magenta Book (1.9) not all interventions will require the same level of scrutiny or have the same learning needs. High-risk, high status policy breaking new ground is likely to require a large-scale evaluation (such as a pilot and investments that are scrutinised by PIC).

While low-risk, well-evidenced and low priority interventions may only necessitate a light-touch monitoring and evaluation exercise to ensure it has been delivered as intended and achieved the predicted outcomes. The RPC proportionality guidance and Magenta Book supplementary guidance for conducting regulatory post implementation reviews discuss the levels of evidence required for post implementation reviews.

# Assess what evaluation evidence is needed, who will use it, and when will it be required

It is important to have a clear idea from the start about the intended use and audience (see 1.10. in the Magenta Book) for the evaluation: what will the findings feed into and inform? When is the information required by different stakeholders? This will help direct all stages of the evaluation and ensure maximum impact from the findings and should be set out in the monitoring and evaluation plan, aligning with the high-level project timetable.

Assumptions tend to occur in three categories: 1. Related to causality – what you think is going to lead to what 2. Programme implementation – how you assume it will be implemented 3. External factors that you assume will happen and that are necessary for success.

Links to resources:

- The Magenta Book
- Proportionality in Regulatory Submissions Guidance
- The Magenta Book
- The Magenta Book

# BEIS Monitoring and Evaluation Framework

To ensure the evaluation provides useful evidence, it is important to consider the requirements of the users of the findings before the evaluation commences so it can be designed to answer these specific questions and deliver findings when they are needed.

When developing the evaluation plan, it is important to understand:

- Who the target end-users of the findings will be – e.g. project/programme managers and the project/programme board; other policy managers and analysts within BEIS; other government departments; delivery bodies; key stakeholders including industry bodies and energy suppliers, local community groups, etc.
- When findings are required, and the timing of decisions they need to feed into – e.g. whether to roll out the pilot, improvements and learning that can help decide whether to invest in future programme waves, or inform Spending Review prioritisation
- What form of evidence is required – e.g. a quantitative cost-benefit assessment of impacts may be required by HM Treasury, while detailed information about effective delivery mechanisms may be sought by project/programme managers of similar policies

By understanding the range of requirements for the evaluation and their relative priority, the evaluation can be tailored to generate the relevant evidence to the required timescales, and/or (just as importantly) a decision can be taken early about the questions which can realistically be answered in the desired timescales.

# Identify the evaluation objectives and questions

The next step is to clarify the evaluation objectives, and what questions the evaluation needs to address.

Evaluation Objectives

Evaluation objectives need to be clearly defined and meaningful to narrow the focus of the evaluation and ensure that the findings are relevant to decision makers.

Returning to the Theory of Change should help you formulate the evaluation objectives and specific evaluation questions, since this will have identified the anticipated outcomes and impacts and the underlying assumptions that might need to be tested, and the evidence gaps that need to be filled.

Spending reviews typically take place every two to five years. They normally set departmental budgets for three to five years ahead and shape the scale and nature of public service programmes and public investment.

# BEIS Monitoring and Evaluation Framework

Examples of evaluation objectives include:

- Offering ‘lessons learned’ to inform development of the planned main Heat Network Investment Project (HNIP) pilot scheme and any future similar schemes
- Identifying what economic and social impact the Catapult activities have had; understanding the contribution made from the Catapult to businesses, academia and the wider research community
- Understanding the impact of providing additional funding to Local Authorities to target energy efficiency installations among private rented sector (PRS) properties within the Green Deal Communities project

Evaluation questions Evaluations can be designed to answer a wide range of potential questions. It is important to be clear from the outset what these questions are and how the findings from them are expected to be used, by whom and when. This will define the scope of the evaluation and inform the evaluation approach. Well-developed evaluation questions should reflect the objectives of the evaluation, the objectives of the intervention, as well as the priorities and evidence needs of stakeholders.

Questions that will help with the development of the evaluation questions include:

- How will you determine if the intervention is a success?
- How will you know if the intervention is on track?
- Do you need to understand why the intervention does/does not achieve anticipated outcomes?
- What contextual factors might affect delivery (e.g. economic climate, other policy - measures, innovation developments, etc)?
- What learning from this intervention could be transferrable to other policies or future waves?

Heat networks typically convey hot water from a shared heat source (or sources) to meet demand for space and water heating, and space cooling distributed across a number of buildings. Heat networks are important because they can provide an opportunity for greater energy efficiency, lower prices for consumers and carbon savings compared with conventional gas or electric heating. The Heat Network Investment Project is a funding mechanism that responds to the current low levels of heat networks in place and the difficulties relating to financial investment. Above all, the aim of HNIP is, alongside other measures, to contribute to the establishment of a self-sustaining UK heat networks market that does not require Government subsidy. See: Heat Networks Investment Project Evaluation

The Catapult centres are a network of world-leading centres designed to transform the UK's capability for innovation in specific areas and help drive future economic growth, see Catapult Programme Evaluation Framework

Evaluation of the Green Deal Communities Private Rented Sector Funding

# BEIS Monitoring and Evaluation Framework

Examples of evaluation questions include:

- What has worked well, less well and why?
- To what extent and how have the anticipated outcomes been achieved?
- How has the context influenced outcomes?
- How much of the impact can be attributed to the intervention?
- Have different groups been affected in different ways, how, why, and in what circumstances?
- Is the intervention a good use of resources?

A long list of evaluation questions should be developed, which can then be grouped by theme and prioritised into a smaller number of high-level questions under which the more detailed questions will sit, according to:

- How important they are to stakeholders (those funding, designing, implementing, or impacted by an intervention)
- Whether they reflect the objectives of the policy and wider departmental priorities
- Whether they reflect the key elements of the Theory of Change
- Whether answering them will provide the information required at key decision points
- Whether answering them will fill evidence gaps
- Whether they will provide information which can be acted upon to make delivery improvements
- Whether they can be answered using the available resources (such as budget and staff) and within the appropriate timeframe

# Identify the appropriate monitoring approach

Monitoring data relates to information collected and used as part of the ongoing intervention delivery to understand progress against objectives. Data which is directly useful to those collecting it tends to be better quality than data collected solely for the purpose of research. All projects and programmes should undertake monitoring of appropriate indicators (referred to as ‘measures’ in benefits management).

Monitoring and evaluation are complementary activities, and ideally the design and requirements for each should be considered together, so the comprehensive data needs of the policy can be considered in the round. This will facilitate the collection of relevant and high-quality data and avoid duplication or missed opportunities for the collection of key data. Early

For example, number of applications, number of firms introducing new/improve products and services, number of smart meters in homes and small businesses across Britain, or % of people with smart meters who say they’ve taken steps to reduce their energy use, number of jobs safeguarded.

# BEIS Monitoring and Evaluation Framework

Identification of any existing data or other ongoing data collection processes that can be utilised for the evaluation will ensure best use of resources and effort.

Create a reporting plan for monitoring data. Regular reporting (e.g. through monthly highlight reports to programme boards, or more frequent updates to key stakeholders) of key performance indicators will provide management assurance that an intervention is on track. Using emerging evaluation evidence to understand why this is the case, the evidence can inform changes to the intervention to manage performance and help realise the anticipated benefits.

To achieve the benefits of monitoring and evaluation, it is important that the evidence flows to the right decision makers (policy and other stakeholders) at the right time. Interventions often conduct annual reviews, an assessment of policy progress, including against agreed milestones. See the Smart Metering Implementation Programme Progress Report and the UK Climate Finance Results.

At departmental level, BEIS’ vision for internal reporting is that all directorates and full business cases that have been approved by PIC have at least one indicator to measure achievements of outputs that should be regularly reviewed and used in reporting to Cabinet Office.

All directorates and programmes/projects in the departmental portfolio are required to complete a performance report each month, for submission to the Portfolio Office via the Department’s Online Reporting in BEIS (ORB) system. Through this, P&R assesses the performance of Directorates and Partner Organisations, and commissions reviews, stocktakes and deep dives to further scrutinise the performance of specific policy commitments, programmes and projects.

Creating appropriate indicators. Monitoring is underpinned by the selection of appropriate indicators. They should be SMART, use good quality established data sources and be proportionate. They should also reflect the direct consequence of the activity undertaken - this can be difficult for outcomes and impacts which can be affected by other activities. Figure 6 shows the basic principles to be considered when identifying an indicator or a series of indicators.

Principles of a good indicator
Simple – it should have a clear definition and be easy to measure, such pat its calculation and interpretation can be easily understood in pe same way by different parties wipout any complicated context. A small number of indicators pat cover only pe important factors are easier to collect and for stakeholders to engage wip.
Relevant – it should reflect only what can be controlled, be clear about how pat activity can influence pe indicator, and about what good progress looks like. This can be achieved by relating to pe intervention’s Theory of Change, alpough wider effects have increasing influence along pe impact papway.

Sources: Smart Meter Progress Report 2018, UK Climate Finance Results

# BEIS Monitoring and Evaluation Framework

3. Timely - it should use regularly available data that does not have any lag which is difficult to explain.

4. Reliable – it should be objectively verifiable, use a good quality data source and be applicable over time. It should also be robust, and not overly sensitive, for example to noise. It should also stand up to external scrutiny.

5. Comparable - it should be readily trackable over time, but also be consistent with other indicators within a policy area, and across the department. This should feed into a logframe (see 3.2.3.8 Identifying data requirements for monitoring and evaluation) and a Key Performance Indicator (KPI) framework against which projects and programmes can report.

While indicators associated with inputs and outputs are typically used in performance monitoring, outcome and objective indicators are most suited to longer term policy impact. However, many impacts may not be realised for some time after implementing the intervention. It is important to use the Theory of Change to understand the pathway to impact and what is needed to achieve the ultimate objective. For early-stage monitoring, this may mean relying upon input and/or output indicators, which will often be easier to record sooner and more frequently. These therefore can be used to indicate progress towards longer term objectives, and to inform any outstanding policy development or implementation decisions.

# Identify the appropriate evaluation approach

Types of evaluation used in BEIS are outlined in 2.2.1. The initial step in deciding on evaluation approach should always be to clearly articulate the objectives and questions for the evaluation, the context and the information or data available; decisions on the approach and methodologies then follow.

Reviewing the evaluation questions will help inform the type of evaluation required. The scale and depth of the questions will inform whether the evaluation needs to be a full impact, value for money and process evaluation, a light touch assessment, or somewhere in-between (see 3.2.3.3).

Additionally, the level of intervention activity and the availability of data may constrain the number of questions an evaluation can realistically answer and type of evaluation which can be conducted (see the Magenta Book38 for further information).

# Identify data requirements for monitoring and evaluation

Monitoring and evaluation data requirements should be built in from the start of any intervention, so that collection processes are established alongside policy design and related legislation. This includes accounting for legal, ethical, and practical issues associated with the data collection. It will often involve building the collection of data, to required standards, into delivery arrangements with external partners. Relevant evaluation data would then normally be collected before the intervention starts (baseline), during the delivery (interim), and after completion (follow-up), to allow ‘before and after’ change to be assessed. The exact length of time for collection of ‘after’ data should be aligned with when outcomes and impacts are expected to materialise.

38 https://www.gov.uk/government/publications/the-magenta-book

# BEIS Monitoring and Evaluation Framework

It may be possible to address some evaluation questions using data collected after delivery, but this tends to result in weaker designs and less robust findings. For example, asking people retrospectively to remember what they did or thought sometime before the intervention was delivered is an unreliable method of measuring behavioral or attitudinal change.

First consider what sources of data already exist and may be appropriate for monitoring and evaluation. You may need to weigh up the quality and usefulness of existing data (e.g. Local Authority, existing survey, or administrative data) against the practicality and feasibility of collecting new data to assess outcomes (see chapter 4 for the Magenta Book for further information).

# Creating a logical framework (logframe)

Theories of Change provide a basis for the development of a monitoring logical framework (logframe). Impacts, outcomes, and outputs from the Theory of Change should all have appropriate indicators to show what is being measured. They also need milestones and targets to show the desired value or direction of progress, and baselines to show the starting point and a source. KPIs should then be recorded in ORB. The basic indicator principles are:

- Use existing sources of information where available
- Indicators should be specific and measurable
- Indicators should be disaggregated where possible (such as by size/type of business, geography, age, gender, ethnicity, disability – specific to intervention objectives)
- Consider including both quantitative and qualitative indicators
- Logframes should be developed with delivery partners and responsibility for data collection built into delivery contracts

Arrangements will need to be negotiated and sometimes legislated. Commercial sensitivity, consent, data validation, transfer and storage and disposal will need to be considered carefully. Baseline data (collected at a time point before the policy is implemented) will commonly need to be collected from participant and non-participant groups. There can be costly consequences of leaving this too late.

# BEIS Monitoring and Evaluation Framework

|PROJECT NAME|World Bank Partnership for Market Readiness (PMR)|
|||
|IMPACT|Impact Indicator|Baseline (31 Oct 2016)|Milestone|Milestone (31 Oct 2020)|Target|
|Substantial CO2 abatement as a result of market mechanisms|(KPI 11)|(May 2011)|Planned|E2.3m|E4.6m|£7m|
|Impact Indicator 2|Baseline|Milestone|Milestone 2|Target|
|Extent to which ICF intervention is likely to have transformational Impact.|(Qualitative KPI 15)|(May 2011)|(31 Oct 2016)|(31 Oct 2018)|(31 Oct 2020)|
|OUTCOME|Outcome Indicator|Baseline|Milestone|Milestone 2|Target|
|Market mechanisms in at least developing countries by 2020.|No. of participating countries implementing market mechanisms|Planned| | |Source: PMR Secretariat Partnership Assembly meetings PMR website|
|Outcome Indicator 2|Baseline|Milestone|Milestone 2|Target|
|Quantity of emissions reductions (in MtcO2e) directly resulting from implementation of market mechanisms supported by the PMR| |Planned|TBC|TBC| |Source: PMR Secretariat Partnership Assembly meetings PMR website|

A good logframe should:

- Have at least one indicator per impact, outcome, activity, and output
- Include indicators that are relevant and appropriate to their impact, outcome, or output
- Have distinctly labelled indicators
- Have clear, measurable indicators
- Detail a baseline for each indicator
- Detail targets and milestones (including month and year) for each indicator and record whether these are achieved
- Indicate when they will be updated
- Include a clearly labelled source and identify who is responsible for collecting the data for each indicator

Impact indicator 2 KPI 15 measures ‘transformational change’. The ICF will have greater impact if it can be ‘transformational’ by, for example, encouraging others to replicate and scale-up successful activities and facilitating substantive institutional and policy change toward a low carbon and climate resilient future. ICF programme/portfolio managers should annually report an overall assessment score of the likelihood that transformation is linked to the ICF support (programme, country, region or sector portfolio) and a qualitative narrative.

When identifying key indicators time should be taken to ensure they are the most appropriate to measure progress against the policy objectives; for example, should you be collecting gross or net data? Will patents signify commercial applications within your timeframes?

# BEIS Monitoring and Evaluation Framework

Any targets and milestones that cannot be set initially should state TBC and the risks and assumptions identified in the Theory of Change should also be actively monitored through risk indicators so that mitigating actions can be taken if required.

Define indicator methodologies

It is best practice to agree methodologies for the data collection to inform your indicators, providing a rationale for data collection, defining what should and should not be included, and explaining what will be reported. This should facilitate data consistency and quality and be included in guidance for those conducting the data collection.

See International Climate Finance results indicator methodologies here.

Monitoring data for regulatory post-implementation reviews

Monitoring data can provide a relatively light-touch evidence base for a regulatory Post Implementation Review (PIR), which is particularly useful in cases where it is not proportionate to undertake substantial primary data collection or additional analysis. In some cases, monitoring information relevant to a regulation may already be captured on a regular basis. In other circumstances, it will be necessary to plan to ensure that the data that will be useful for a PIR are collected.

Evaluation data

Good quality evaluations are only possible with consistent, accurate and complete data. In addition to monitoring and administrative data, this would often include new data collected specifically for the evaluation, including data to inform any value for money assessment. It is important to note that an impact evaluation will often require data to assess the counterfactual, i.e. data from a comparison or control group (e.g. businesses or households) who are not affected by, or in receipt of, the intervention. Information from such groups can often be challenging to obtain.

The data required for an evaluation will be used to assess the inputs, outputs, outcomes and impacts of the intervention. It will also be used to test how these elements are linked together (i.e. the processes and assumptions). Generally, baseline (i.e. pre-intervention) data will be required to show what changes have occurred since the policy has been implemented to assess changes in attitudes and behavior, for both ‘treated’ and comparison or control groups.

Quantitative data would normally be collected to assess change in outcomes in both the ‘treated’ and counterfactual groups – e.g. surveys conducted before and after intervention implementation to assess change in attitudes and behavior.

Qualitative data should be collected to assess implementation processes and whether anticipated outcomes and impacts have materialized (those which cannot be assessed quantitatively); identify any unintended outcomes, recognize the influence of wider contextual factors, or participants’ experiences or perceptions of implementation; and examine the processes involved in transforming inputs into outcomes to understand what works for whom, how, and in what context.

Further information on evaluation data collection, including secondary data and matching data can be found in appendix A5.

Secure the resources

As already mentioned, a judgment needs to be made about the scale and form of evaluation that is required for an intervention, including whether it should be commissioned externally or

# BEIS Monitoring and Evaluation Framework

Conducted (either partly or wholly) in-house. In some circumstances, it may be useful to undertake a scoping or feasibility study to support this decision-making process. This form of assessment can foster greater understanding of what can and cannot be evaluated, and therefore what level of investment is required and can support the development of an appropriate evaluation design for large or complex evaluations.

All evaluations, even those commissioned to an external contractor, will require significant internal input to ensure they are designed and delivered successfully. Several resources will need to be considered, as follows:

- Financial resources: It is important to think about the budget and resources required for evaluation early, as part of the PIC business case. It should be noted that a substantial part of the evaluation costs can often be incurred after the intervention delivery has completed. It is not possible to give a fixed sum or proportion of budget for evaluation, as it will vary with the considerations above and the type of data required. Externally commissioned evaluation budgets can range from tens of thousands to millions of pounds depending on the level of evidence and resource required. It is important to bear in mind that collection of new data is costly – particularly if large-scale survey and/or qualitative data collection are required.
- Management and ownership: In keeping with the Aqua Book43 principles (the Aqua Book is the cross-Government guidance on quality analysis (QA)), the BEIS Evidence Framework is a QA approach with clear and explicit roles and responsibilities, where QA is continuous and proportionate and there is an explicit audit trail that records the evidence sources, review and clearance associated with evidence and analytical products.

The Framework includes standard roles that are applied to any analytical activity in BEIS:

Senior Responsible Officer (SRO), often pe budget holder, who holds overall accountability for pe success of pe project.
The Assurer, a senior analyst wip responsibility for sign-off analysis plans and clearing pe analysis outputs prior to submission to pe SRO.
The Project Manager, pe day-to-day project manager is responsible for ensuring pe required project QA takes place. Evaluation managers need to have capabilities in four areas: scoping, leading and managing, mepods, and use and dissemination (see chapter 7 of pe Magenta Book for more information44).
Peer Reviewers are independent analysts wipin BEIS who review pe analysis and use of evidence and make recommendations for improving pe analysis. In some cases, particularly for complex or controversial policies or evaluations, peer review is also advisable at pe design stage to ensure pe best quality evaluation design is being used and to demonstrate openness and transparency.
Peer reviews by external evaluation experts are also required for all BEIS evaluations prior to publication, see 4.5.
Project teams assign roles according to pe Evidence Framework. They will also follow QA procedures for peir team, Directorate or Group, as appropriate for pe project.

43 https://www.gov.uk/government/publications/the-aqua-book-guidance-on-producing-quality-analysis-for-government

44 https://www.gov.uk/government/publications/the-magenta-book

# BEIS Monitoring and Evaluation Framework

The level of input required will be greatest at key points (in particular, the design and commissioning stages), but throughout monitoring and evaluation there is an ongoing resource requirement that should not be underestimated.

Steering groups: Establishing a steering group for the evaluation will help ensure it is designed and managed to meet the requirements of relevant stakeholders and remains on track. A steering group will usually include the policy lead(s) and relevant team members, analyst(s) supporting the evaluation, the economist responsible for the project appraisal, key delivery partners, other government departments, etc.

Steering groups are particularly important for large-scale evaluations, but this type of scrutiny and support is always useful, even for light-touch evaluations. Existing governance groups could be utilised in these cases.

Delivery bodies: A successful evaluation will depend on the engagement and cooperation of those organisations and individuals involved in delivery of the programme, in many cases they will be the face of the policy and will have huge impact on the data quality and its usefulness for monitoring and evaluation. It will be important to work with delivery stakeholders to ensure they are aware of, and signed up to: what the monitoring and evaluation seeks to address, how, and what input will be required from them; and how they can potentially benefit from the findings, for example, by sharing data or taking part in interviews. As part of the monitoring and evaluation plan, you should consider the burden being put on stakeholders, and how this can be minimised.

# Conduct or commission the evaluation

As highlighted above, the evaluation should be managed by a dedicated internal project manager and a monitoring and evaluation plan should be included in a PIC business case and a summary included in a regulatory impact assessment.

The necessary steps for an externally commissioned evaluation are as follows:

Define pe terms of reference and establish pe steering group
Obtain procurement and Research Committee approval – pis is required for all commissioned evaluations, see 4.2.1
Write pe evaluation specification: pis should set out pe background and objectives to pe policy; clarify pe evaluation scope and questions; and indicate pe size, scale and timing and deliverables for pe evaluation, agreed by pe programme lead, analysts and oper key stakeholders
Commission (see chapter 5 of pe Magenta Book45) pe evaluation via a competitive tendering exercise
Inception and ongoing management: an inception meeting wip pe contractor and steering group to clarify pe scope of pe work, timings, expectations for outputs and arrangements for ongoing management. Steering group meetings should be scheduled at appropriate decision and reporting points for pe evaluation. The process for regular progress reporting should also be agreed.

Magenta Book

# BEIS Monitoring and Evaluation Framework

An internally conducted evaluation should follow similar steps of having defined terms of reference and a project specification.

# Use and publish the evaluation findings

At the time of planning an evaluation it is a good idea to give some thought to how the findings will be used and disseminated. BEIS expects all our evaluations to adhere to the Government Social Research Protocol, which has five principles:

- Principle 1. The products of government social research and analysis (which includes evaluation) will be made publicly available
- Principle 2. There will be prompt release of all government social research and analysis
- Principle 3. Government social research and analysis must be released in a way that promotes public trust (findings should not be influenced by political concerns)
- Principle 4. Clear communication plans should be developed for all social research and analysis produced by government (departments should publicly announce what research projects have been commissioned and publish high-level information regarding those projects)
- Principle 5. Responsibility for the release of social research and analysis produced by government must be clear (in BEIS’ case that would be the Government Social Research Heads of Profession)

As outlined in the following chapter BEIS requires all externally commissioned evaluation reports to be sent for independent peer review prior to publication, and reviewers’ comments to be addressed.

As well as publication, other ways of disseminating and using the evaluation evidence should also be considered early and reviewed regularly by the steering group, such as identifying the best communication channels, and outputs, to reach users. One-page summaries, video outputs, infographics and engaging tools can be considered to help key messages reach the right audience. The format of outputs should be agreed with all evaluation stakeholders, inform delivery and key decision points and feed into new policy development.

Evaluation project closure procedures facilitate the use of findings:

- all quantitative evaluation data should be appropriately anonymised and submitted to the national Archive to facilitate further analysis
- all relevant materials should be submitted to BEIS’ internal online database of key analytical documents
- BEIS evaluation reports should be published on gov.uk or devtracker
- external expert peer review comments that are not addressed should be published
- evaluation outputs need to be easily accessible for policy makers and available when they can influence decisions

Sources: Government Social Research Publication Protocols, Devtracker

# BEIS Monitoring and Evaluation Framework

• every report should have a transparent technical annex, so findings could be replicated Designing and conducting an evaluation after an intervention has been implemented does happen, but there are risks (a robust evaluation might not be possible) and the quality of the evidence is likely to be poorer. It will be necessary in this situation to identify what relevant information is available, e.g. data collected as part of ongoing performance monitoring and/or administrative data. However, this often misses baseline data, collected before the intervention was implemented, or data collected for a comparison or control group. This will result in a less robust assessment of the policy being possible, and key questions, such as ‘would the outcomes have happened anyway?’ being unanswerable. Nonetheless, it will normally be possible to undertake some assessment of the delivery process and immediate outputs of an intervention if the evaluation is planned and undertaken after policy implementation.

For further information in the use and dissemination of evaluation findings see chapter 6 of the Magenta Book.48

48 https://www.gov.uk/government/publications/the-magenta-book

30

# BEIS Monitoring and Evaluation Framework

4. Achieving the BEIS monitoring and evaluation vision

BEIS is a diverse department with a wide range of policy areas and responsibilities, many of which are implemented through delivery partners. We need to build on our successes so that best practice in monitoring and evaluation is extended across all our work to influence policy implementation and design.

Earlier chapters set out the steps required to achieve effective monitoring and evaluation. This is supported by a range of governance processes outlined below, including using the BEIS Peer Review Group to provide independent, transparent quality assurance of findings. We are also continuing to build capacity and capability amongst policy and analytical colleagues, which will contribute towards a positive learning culture. These are discussed in turn below.

# 4.1 Establish comprehensive monitoring and evaluation coverage

As stated previously well-developed monitoring and evaluation are important for learning and accountability. Monitoring and evaluation learning should inform and influence better policy implementation and decision-making across the department to achieve its objectives.

# 4.1.1 Requiring monitoring and evaluation plans

BEIS is committed to investing in monitoring and evaluation as tools for assessing and improving current and future policies across our policy areas. We aim to provide an open and transparent view of monitoring and evaluation coverage of BEIS interventions and support good quality evaluations.

BEIS requires monitoring and evaluation plans in all its PIC business cases for interventions that meet the criteria for the Departmental Portfolio and are considered by PIC and a more detailed PIR review plan to be completed for all high impact regulatory impact assessments in addition to the summary plan included in the impact assessment.

# 4.1.2 Encouraging best practice in our partner organisations

BEIS is a ministerial department supported by 41 partner organisations (POs). These range from large organisations such as UK Research and Innovation and the Nuclear Decommissioning Authority, through medium-size organisations working on regulation such as the Competition and Markets Authority, to advisory committees including the Committee for Climate Change. A significant proportion of BEIS’ expenditure is through POs, for which BEIS is ultimately accountable to Parliament.

Source: https://www.gov.uk/government/organisations#department-for-business-energy-and-industrial-strategy

# BEIS Monitoring and Evaluation Framework

POs are responsible for the monitoring and evaluation of the policy areas which they deliver. Given the importance of POs in the delivery of our policies and investment, the department encourages best practice monitoring and evaluation in our partner organisations.

To do this, the department:

- Encourages POs to work together with policy teams in BEIS to produce monitoring and evaluation plans, before policy implementation, so that good quality evaluation evidence is possible, and the supporting data can be successfully collected
- Shares best practice and quality standards with POs
- Reviews and collates information about POs’ monitoring and evaluation coverage and quality

# Embed monitoring and evaluation into governance processes

To ensure proportionate monitoring and evaluation is delivered, even in challenging circumstances, BEIS needs to firmly embed monitoring and evaluation in governance processes. This section outlines BEIS’ current governance processes for monitoring and evaluation, which will be reviewed and strengthened.

# Evaluation governance

There are several governance processes that apply to the commissioning and implementation of research and evaluation projects in BEIS.

|Project scoping|Business Case|Procurement|Research Design|Data Collection|Analysis|Reporting & Dissemination|Publication|
|||||||||
|BEIS Research Committee|Steering Groups|Evaluation|GSR Publication|Protocol| | | |

A scoping exercise initiates the commissioning of research (including evaluation), and a Project Initiation Document (PID) is developed as a product of the exercise for senior stakeholders/owners to give direction on whether the project should go ahead.

Research and evaluation projects with a budget of over £10k are required to seek procurement and BEIS Research Committee approval before they can be procured. Those below this amount follow their policy team approval procedures.

# BEIS Monitoring and Evaluation Framework

The BEIS Research Committee is made up of senior analysts who quality assure and approve the commissioning of new research and consultancy in core BEIS, including evaluations, by reviewing research business cases. The Committee reviews the rationale for the research, how it fits with the existing evidence base, how the findings will be used and learning shared, the proposed methodology, risk management and quality assurance.

Approved research and evaluation projects should inform project and policy development and implementation. The findings from these projects should be included as evidence in investment business cases and impact assessments.

During a project policy teams will follow their own quality assurance procedures in line with the BEIS Evidence Framework. They will also convene steering groups at key stages during the research to quality assure and influence strategic decisions. Further detail on both these measures can be found in 3.2.3.8.

Prior to publication all evaluation reports are submitted for external peer review by evaluation experts. Reviewers’ comments are then addressed ahead of publication, see 4.5 for more information.

Finally, all BEIS research and evaluation projects are expected to adhere to the Government Social Research (GSR) Publication Protocol as outlined in 3.2.3.10.

# Investment governance

The BEIS Projects and Investments Committee (PIC) scrutinises and approves significant, risky or contentious investments of taxpayer funds undertaken by the department. If PIC approval is not required, the Business Case should follow the Director General Group’s procedure for spending approval.

|Business Case Development|Keyholder review and agreement|Project Investment Committee (PIC) Approval|
||||
|PIC approval not required|Follow Director General Group’s procedure for spending approval| |

If PIC approval is required, the first stage is the keyholder stage where experts from across the department review business cases to assess whether they provide PIC with enough information to make an informed decision. A monitoring and evaluation plan is part of the management case in a business case. P&R provides assurance on the performance and delivery of BEIS’s major programmes and the overall portfolio of BEIS projects.

Operational researchers, statisticians, social researchers, economists, scientists, engineers and policy leads depending on topic and specialism.

Projects with Whole Life Cost over £20m (or other delegated authority where it applies).

# BEIS Monitoring and Evaluation Framework

Departments and partner bodies are required to produce impact assessments (IAs) assessing the costs and benefits of regulatory changes prior to consultation, enactment, and implementation. The evidence and analysis used within IAs are scrutinised by the independent Regulatory Policy Committee (RPC).

An impact assessment summarises the rationale for government regulatory intervention, objectives, the options considered and the expected costs and benefits. This information is crucial to inform policy decisions.

In 2011 it became mandatory to include a review clause in any legislation that regulates business and civil society organisations (referred to as ‘business’) except where the effect is deregulatory or the net costs or benefits to business are less than or equal to £1 million in any given year (in 2017, this was increased to £5 million). This was part of the Government’s commitment to reduce both the stock of existing regulation and the flow of new regulation.

Review clauses impose a statutory duty to carry out a review of the relevant legislation within a specified timescale. In most cases, the date of publication of the statutory review is no later than five years from the date the legislation came into force, and subsequent reviews should take place at five-year intervals, at most.

The level of evidence required for both IAs and PIRs is based on the scale of impact, contextual factors, and existing evidence base. Those with a high impact require Central Analysis on behalf of or BEIS Director of Analysis sign-off, prior to ministerial sign-off.

|Figure 10: Regulatory governance| | |
||||
|IA/PIR and Clearance Statement Development|Submit for Central Analysis Team review|Submit for Chief Analyst sign-off|
|Chief Analyst sign-off not required|Follow policy team analytical sign-off procedures| |
|Submit for Special Advisor and Ministerial sign-off|Submit for Regulatory Policy Committee opinion|Submit for cabinet write-round|

Further information on PIC and P&R can be found in 3.2.1. The evidence in PIC business cases should build on previous monitoring and evaluation learning.

Further information on post-implementation reviews (PIRs) can be found in 3.2.2.

52 An independent body sponsored by BEIS which assesses the impact on business of new regulatory and deregulatory proposals: https://www.gov.uk/government/organisations/regulatory-policy-committee/about

53 https://www.gov.uk/government/collections/impact-assessments-guidance-for-government-departments

54 https://www.gov.uk/government/publications/better-regulation-framework

55 an equivalent annual net direct cost to business (EANDCB) or Net Present Value (NPV) of greater than +/- £50 million

56 an equivalent annual net direct cost to business (EANDCB) or Net Present Value (NPV) of greater than +/- £150 million, or that are high profile, novel or risky approaches, based on untested assumptions, or where learning will directly inform future policy making.

# BEIS Monitoring and Evaluation Framework

publication57. Those that do not require this level of sign off follow their policy team analytical sign off procedures. The evidence and analysis used within PIRs over a certain size58 are also scrutinised by the independent Regulatory Policy Committee (RPC).

Final versions of IAs and PIRs are published on legislation.gov.uk, alongside the relevant IA(s) and any59 RPC opinions on the quality of evidence. PIRs should also be published on gov.uk.

# Build policy and analytical capacity and capability

To facilitate coverage and embed learning that informs and influences better policy implementation and decision-making across the department, BEIS takes several measures to build the monitoring and evaluation capacity and capability amongst its policy officials and analysts.

BEIS offers internal monitoring and evaluation training for policy colleagues.

BEIS also takes several measures to increase analytical evaluation capacity and capability:

- Evaluation training is part of core training for BEIS analysts to ensure our analysts have the skills required to deliver evaluations
- BEIS has an internal Evaluation Practitioners Network (EPN). The network meets monthly to support the delivery of good quality evaluation in BEIS through shared knowledge and learning
- BEIS has an External Peer Review Group (PRG) comprised of independent evaluation experts who review our reports prior to publication and can be consulted at key stages of evaluation projects, especially to review evaluation designs. Their comments increase the capability of individual project managers and the wider analytical community, as they are stored centrally and accessible to the wider department, see 4.5 for more information

To share knowledge and learning BEIS sits on cross-government groups:

- The Cross-Government Evaluation Group (CGEG) aims to improve the supply of, stimulate demand for, and encourage the use of, good quality evaluation evidence in government. The purpose of this is to improve policy development, delivery and accountability across government. CGEG is a cross-departmental, cross-disciplinary group, with representation from most major departments
- The Cross-Government Monitoring, Evaluation and Learning Official Development Assistance (ODA) Group is a knowledge exchange with monitoring and evaluation

# BEIS Monitoring and Evaluation Framework

Advisers across government working on ODA – an overseas aid budget to support and deliver the government’s 2015 Aid Strategy in developing countries.

# 4.4 Facilitate a positive learning culture

The effectiveness of our policies depends on a strong and safe culture for monitoring and evaluation, where timely and accurate feedback and analysis assess what effect the intervention has had, how, why, and for whom, and this learning is fed back rapidly into policy decisions. Learning and feedback are therefore pivotal elements of a successful monitoring and evaluation framework.

An important part of this learning process is to acknowledge that when policies do not deliver the desired effects – indeed, even when they produce unexpected or unwanted effects – these are still valuable opportunities to develop our knowledge, so we can refine and adapt future policies and eventually secure better outcomes. BEIS must enable this flow of information as far as is possible. This is about reinforcing existing good practice to make the learning process integral to the way we work in BEIS.

Our aim is to increase the number of evaluations that inform and influence better policy delivery and decision-making across our policy areas. This is facilitated by an internal online database of key analytical products from the policy cycle which are stored centrally, in real-time, coded, and searchable, creating links across policy areas and between appraisal and evaluation.

# 4.5 Maintain independent, transparent quality assurance of findings

The BEIS External Peer Review Group (PRG) helps BEIS maintain independent, transparent quality assurance of findings. The group is comprised of independent evaluation experts. BEIS requires all evaluations to be sent for independent peer review prior to publication, and reviewers’ comments to be addressed.

Two peer reviewers with expertise in the relevant policy area and evaluation methodologies are invited to comment on evaluation reports prior to publication and evaluation teams work with them to address their comments in the published version of the report. Where all comments are not addressed a summary of the review should be published alongside the report.

BEIS also encourages teams to consult the PRG at key stages of the evaluation projects, especially at the earliest stages of scoping and design. This independent scrutiny provides assurance of quality and increases the credibility of our work.

Publications also include detailed and transparent technical annexes, with data published, where possible, to allow further independent scrutiny of BEIS evaluations by external experts.

BEIS regularly reviews and refreshes the PRG, by direct invitation from the department, to ensure appropriate capacity levels and give policymakers access to a broader range of expert advice.

# BEIS Monitoring and Evaluation Framework

5. Next steps

BEIS recognises the value of monitoring and evaluation. While there are several examples of good quality assessments in the department, BEIS aims to expand this across our policy areas to inform and influence better decision-making within the department to achieve its objectives.

This will be achieved by further embedding monitoring and evaluation into governance processes, building policy and analytical capacity and capability, and facilitating a positive learning culture. We will also continue to develop and maintain BEIS’ central database: an internal online database of key analytical products from the policy cycle which are stored centrally, in real-time, coded, and searchable, creating links across policy areas and between appraisal and evaluation.

To ensure the departmental approach to monitoring and evaluation is open and transparent we maintain an expert external peer review system and aim to publish key investment monitoring and evaluation activity.

We recognise that it will take time to deliver the Framework in full. This will require consistent demand and expectation for monitoring and evaluation evidence from senior managers and decision makers, adequate resourcing and evaluation capability from our policy makers and analysts, and effective collaboration with our partner organisations. We will need to commit the necessary resources, including administrative resource in both central and policy teams to support this expansion.

37

# BEIS Monitoring and Evaluation Framework Appendices

- A1 Glossary of terms
- A2 BEIS evaluation case studies
- A3 Theory of Change template
- A4 Logframe template
- A5 Further information on additional data requirements and linking
- A6 Regulatory post implementation review plan template

38

# BEIS Monitoring and Evaluation Framework

|Term|Definition|
|||
|Activity|What actions must be taken, and by whom, to produce the required outputs – e.g. what is done by staff to achieve the policy objectives, such as applicant support|
|Analyst|Analyst is a blanket term used to describe several analytical professions that exist within government. Analysts provide comprehensive advice, challenge and insight based on evidence to help meet government objectives. There are four analytical professions in BEIS that commission, manage and quality assure monitoring and evaluation projects: 1) social researchers use the methods of social scientific enquiry to understand how people and businesses think and behave 2) economists assess the costs, benefits and risks of alternative ways to meet government objectives 3) statisticians collect, quality assure, analyse and publish data to help government, business and the public make informed decisions 4) operational researchers look closely at complex systems and develop models that predict the way they behave.|
|Appraisal|Appraisal is the process of assessing the costs, benefits, and risks of alternative ways to meet government objectives.|
|Baseline data collection|Measurement of conditions prior to the implementation of a policy against which subsequent progress can be assessed, such as behaviors, attitudes, employment, turnover, emissions.|
|BEIS|Department for Business, Energy & Industrial Strategy|
|BEIS External Peer Review Group (PRG)|A group of independent evaluation experts who review BEIS evaluation reports prior to publication and can be called upon to review the design of proposed evaluations.|
|Benefit|A measurable positive outcome for one or more stakeholders that is linked to a strategic objective such as an increase in energy security.|
|Benefits management|A program management approach that aims to make sure the desired business change or policy outcomes have been clearly defined, are measurable and provide a compelling case for investment.|
|Benefits map|A logic map, in the form of a visual diagram, used in benefits management to link all the drivers, enablers and business change to the benefits from a project/policy change, and linking benefits to objectives and strategic goals. A benefits map is similar to a Theory of Change used in evaluation.|
|CBA|Cost-Benefit Analysis estimates whether the benefits of a policy outweigh its costs, and by how much relative to other alternatives – usually in comparison to what would have happened without the intervention.|
|Comparison or control group|A group alike to the treatment group in every way.|
|Counterfactual|The counterfactual scenario is what would have occurred in the absence of the policy. The counterfactual scenario cannot be observed, because it is defined as what did not happen. So, the challenge of impact measurement is to find some way to reconstruct what would have occurred in the absence of a program, so we can compare those two scenarios, and determine the true impact.|
|Cost-effectiveness|Social cost-effectiveness analysis compares the costs of alternative ways of producing the same or similar outputs.|
|Data collection|The collection of information to use in monitoring or evaluation; this can be quantitative or qualitative.|
|Evaluation|Evaluation is the systematic assessment of the design, implementation and outcomes of an intervention.|

# BEIS Monitoring and Evaluation Framework

|Evaluation approach|The way that the answering of evaluation questions is approached; for example, impact evaluations may use a theory-based approach and/or an experimental approach.|
|||
|Evaluation design|The overarching design of the whole evaluation, which includes how the evaluation will meet the learning aims specified.|
|Evaluation methods|The way that information is collected and analysed in order to test theories and answer the evaluation questions (e.g. difference in difference, modelling, randomised control trials).|
|Evaluation questions|Evaluation questions are high-level questions that an evaluation is designed to answer.|
|Evaluation types|The types of evaluation are defined by the evaluation questions. Common types of evaluation include process, impact, and value for money.|
|Experimental evaluation|These evaluation designs are referred to as randomised control trials (RCTs). Treatment and control groups are randomly assigned. The aim is that the only difference between the treatment and control groups on average is that the control group does not receive the intervention.|
|Impact|The ultimate result to which the policy contributes. Impact is defined as a change in social, environmental, or economic outcomes (positive or negative) that is directly attributable to an intervention, such as reduced energy costs or change in employment.|
|Indicators|What you might want to know or expect to see to indicate you were on track to achieve your benefits and impacts, such as number of applications, number of firms introducing new/improved products and services, number of smart meters in homes and small businesses across Britain, or % of people with smart meters who say they’ve taken steps to reduce their energy use.|
|Input|What the policy is expected to provide such as grant funding or equipment.|
|Intervention|Anything intended to elicit change, including a programme, policy, project, regulation, and changes in delivery method, such as activities to mitigate climate change, set a minimum wage or funding to stimulate productivity in the UK economy.|
|Monitoring|Monitoring is the ongoing collection and analysis of data (specified indicators) about an intervention to understand progress against its objectives.|
|Net Present Value (NPV)|The sum of future streams of net benefits. These are discounted to bring them into today’s value using the standard rate agreed by the civil service.|
|Outcome|An outcome is any social, environmental, or economic effect that a policy is interested in maintaining or improving in some way. For example, labour force participation or accumulation of knowledge and skills.|
|Output|What is expected to happen as a direct result of the intervention activities, such as the number of projects supported.|
|Performance and Risk Committee (P&R)|The Performance and Risk Committee (P&R) is a delegated Committee of the BEIS Executive Committee (ExCo), which provides assurance for ExCo and the Permanent Secretary on the performance and delivery of BEIS’ programme and policy commitments, as well as its Partner Organisations.|
|Policy|A government policy is an objective or course of action planned by the Government on a particular subject. Policies are usually developed by a Government department, such as BEIS, to achieve their objectives.|
|Policy objectives|How the policy is supposed to affect its various target outcomes.|
|Policy Official|The Policy Profession designs, develops, and proposes appropriate courses of action to help meet key government priorities and ministerial objectives.|
|Portfolio|A portfolio comprises part or all of an organisation’s investment required to achieve its objectives. Governed through its portfolio (or business) plan, a|

# BEIS Monitoring and Evaluation Framework

|Process|Process evaluations tend to examine activities involved in an intervention’s implementation and the pathways by which the policy was delivered. They will often cover subjective issues (such as perceptions of how well a policy has operated) and objective issues (the factual details of how an intervention has operated, typically using administrative data, where available).|
|||
|Programme|A programme is a temporary, flexible organisation created to co-ordinate, direct and oversee the implementation of a set of projects and other work components to deliver outcomes and benefits related to a set of strategic objectives. Programmes can be undertaken in one or more tranches (phases), each of which is structured around distinct step changes in capability and benefit realisation.|
|Project|A project is a temporary management environment, undertaken in stages, created for the purpose of delivering one or more business products or outcomes. A project might be standalone within a portfolio or part of a programme.|
|Project Investment Committee (PIC)|The BEIS Projects and Investments Committee (PIC) scrutinises and approves significant (with a whole life cost of £20m or above either to BEIS or the economy as a whole), risky or contentious investments of taxpayer funds undertaken by the department.|
|Quantitative data collection|Quantitative data collection generates numerical data or data that can be transformed into usable statistics. It is used to quantify attitudes, opinions, behaviours, and other defined variables – and generalise results for a particular population.|
|Qualitative data collection|Qualitative data collection is primarily exploratory. It is used to gain an understanding of underlying reasons, opinions, and motivations. It provides insights into the problem or helps to develop ideas or hypotheses for potential quantitative research. Qualitative Research is also used to uncover trends in thought and opinions, and dive deeper into a topic, opinion or experience.|
|Quasi-experimental evaluation|Quasi-experimental evaluation involves examining the impact of an intervention by taking measurements before and after it is implemented, in a similar way to experimental evaluation. However quasi-experimental evaluations do not randomly assign groups to the treatment and comparison group. Evidence is collected to ascertain whether any change that has occurred can be attributed to the intervention or other causes, controlling for variables that influence the outcome.|
|Regulation|The ongoing processes of monitoring and enforcing the law.|
|Regulatory Policy Committee (RPC)|RPC is an advisory non-departmental public body, sponsored by the Department for Business, Energy & Industrial Strategy.|
|Regulatory post implementation review|A PIR is a process to review a regulation or policy decision after it has been implemented and operational for a period of time. A PIR should assess if the objectives of the regulation have been achieved, if the objectives are still relevant and if they could be achieved in a less burdensome way.|
|Research Committee|The BEIS Research Committee is made up of senior analysts who quality assure and approve the commissioning of new research and consultancy in core BEIS, including evaluations, by reviewing research business cases.|

Sources: Project Delivery Functional Standard

# BEIS Monitoring and Evaluation Framework

|SMART|Specific, Measurable, Achievable, Realistic, Time-bound.|
|||
|Single Departmental Plan|This sets out the department's objectives and how they will be achieved.|
|Spending Review|Spending reviews take place every two to five years. They set departmental budgets for three to five years ahead and shape the scale and nature of public service programmes and public investment.|
|The Aqua Book|HM Treasury guidance on producing quality analysis for government.|
|The Green Book|HM Treasury guidance on how to appraise and evaluate policies, programmes, and projects.|
|The Magenta Book|HM Treasury guidance on what to consider when designing an evaluation.|
|Theory of Change|Theory of Change is essentially a comprehensive description and illustration of how and why a desired change is expected to happen in a particular context. It is focused on mapping out the "missing middle" between a programme or change initiative's activities or interventions and how these lead to desired goals being achieved.|
|Theory-based evaluation|Theory-based approaches to evaluation use an explicit theory of change to draw conclusions about whether and how an intervention contributed to observed results.|
|Treatment group|The group that participates in the policy, also referred to as the test group.|
|Value for Money evaluation|Value-for-money evaluation methods compare benefits to the costs of interventions, including adverse and unintended aspects. Two widely used methods are social cost-effectiveness analysis and social cost-benefit analysis, both of which allow for comparison of two or more alternative options (interventions).|

Sources:

63 Department for Business, Energy and Industrial Strategy Single Departmental Plan

64 The Aqua Book - Guidance on producing quality analysis for government

65 The Green Book - Appraisal and evaluation in central government

66 The Magenta Book

# BEIS Monitoring and Evaluation Framework

A2. BEIS evaluation case studies

# Process evaluation approaches used in BEIS

Process evaluations employ a variety of methods used in the social sciences, normally including both qualitative and quantitative methods. The purpose of a process evaluation is to explain how an intervention generates outcomes or effects. Data collection and analysis in process evaluations are structured around Theories of Change which illustrate the causal pathways thought to be operating in the intervention. These causal pathways are the ‘processes’ of process evaluation.

In BEIS process evaluations are conducted to understand how the effect of an intervention is achieved - how an intervention operates to produce outcomes (what has been achieved). This includes:

- knowing which aspects of an intervention are important
- how different aspects of an intervention work together
- how an intervention can be implemented in a given context

BEIS process evaluations illuminate the mechanisms through which an intervention produces change. This is particularly important if the department aims to roll out an intervention more widely in the future. Findings from a process evaluation can help implementation and adaptation of the intervention, as necessary, to other populations and contexts. A process evaluation can also explain why an intervention failed and indicate how it might be improved.

# Process evaluation case study: The Newton Fund67

BEIS delivers some of the UK government’s Official Development Assistance (ODA). One of these is The Newton Fund68 a £735 million UK investment which aims to support cutting-edge research that addresses the challenges faced by developing countries.

BEIS give allocations to 17 Delivery Partners (UK Research and Innovation, UK Space Agency, the Met Office, British Council, Academies etc.) These Delivery Partners’ primary funding mechanism is through research grants to research institutions.

A process evaluation was conducted in the latter half of 2017. This allowed enough time for BEIS and stakeholders delivering the Fund to learn lessons and make improvements during the remainder of the Fund’s lifetime (until 2021) as well as informing the development of similar programme approaches and other interventions in the future, for example the Global Challenges Research Fund (GCRF).69

The methodologies included a review of programme documents (for example, business case, meeting minutes, progress reports, country strategies, contracts, and procurement), which was used in interviews with key stakeholders (10 BEIS, 15 in-country teams, 15 UK delivery partners, 8 overseas partners). The data was systematically coded, reviewed and triangulated.

67 https://www.newtonfund.ac.uk/about/newton-fund-evaluation/

68 For more information see: https://www.newtonfund.ac.uk/

69 https://www.ukri.org/research/global-challenges-research-fund/

# BEIS Monitoring and Evaluation Framework

The evaluation found that since the initial roll out, the Newton Fund has undergone important developments in terms of how it is run, as well as fine-tuning of its objectives. There is evidence that the Newton Fund supports partnerships that promote economic development and welfare, and that the flexibility around 'match' is one of the key successes.

Recommendations were to:

1. publish a single strategy document to set direction and establish priorities, simplify decision-making, and drive alignment
2. formally document processes and responsibilities, as they are currently understood but not documented leaving scope for inconsistency and inefficiency in delivery in an already highly complex programme
3. maintain momentum to develop a new centralised, semi-automated reporting tool which is critical to more efficient portfolio management, better financial reporting, and transparency

BEIS is addressing these by working on strategy documents, recording processes and responsibilities, and delivering on the reporting tool.

# Impact evaluation approaches used in BEIS

Theory-based evaluation

Theory-based approaches to evaluation use an explicit Theory of Change to draw conclusions about whether and how an intervention contributed to observed impacts and often considers the context at the time that the intervention is being implemented.

Theory-based methods tend to be particularly suited for the evaluation of complex interventions or simple interventions in complex environments. In these situations, where determining the effect size can often be difficult, theory-based methods can confirm whether an intervention had an effect in the desired direction. They can also explain why an intervention worked, or not, and inform translation to other populations, places or time periods.

Theory-based evaluation case study: Transitional Arrangements (TA) for Demand Side Response (DSR) in the Capacity Market (CM)

The TA aimed to encourage the development of Demand Side Response (DSR) to balance supply and demand in a decarbonised electricity grid.

It is a requirement for partner countries and their funding agencies to match (in money, resources, such as facilities or equipment, or effort, i.e. labour) the contributions they are receiving from the UK

Source: https://www.gov.uk/government/publications/the-magenta-book

The Capacity Market is a mechanism introduced by the Government to ensure that electricity supply continues to meet demand as more volatile and unpredictable renewable generation plants come on stream. It will ensure there is sufficient generation or load-management capacity in the system to cope with times of stress on the network when, for example, the wind stops blowing or there is a surge in demand.

# BEIS Monitoring and Evaluation Framework

The evaluation was designed to answer five high-level questions including: What outcomes can be attributed to the TA and were they as intended by BEIS? What outcomes occurred for whom and under what circumstances?

The approach to the evaluation was realist and theory based. The realist approach emphasised the importance of understanding not only whether a policy contributes to outcomes (which may be intended or unintended) but how, for whom and in what circumstances. The development of a ‘theory’ of the TA was central to implementing a realist evaluation as it allowed the rigorous examination of the design and execution of the scheme, and test policy assumptions against available evidence. An initial theoretical framework was developed, setting out the realist hypotheses to be tested.

Evidence was gathered to test and revise the initial theoretical framework. This involved in-depth telephone interviews with representatives of organisations; an email survey on cost information; and case study research. The evaluation found that the first auction will contribute to involvement in other auctions as providers were able to build experience, customer bases and learn lessons about participating in the capacity market. Phase 2 of the evaluation found that a large amount of capacity dropped out after the auction due to difficulties signing up clients and difficulties complying with complex operational tests. Findings from Phase 3 suggest that the second auction stimulated learning about demand reduction or shifting demand to another time period for some participants.

# Experimental evaluation

Randomised Control Trials (RCTs) use randomised access to interventions creating a treatment and control group. They compare outcomes between those two groups to give an indication of the impact of the policy. The control group acts as a proxy for the counterfactual.

RCT evaluation case study: The Business Basics Fund

There is wide variation in productivity across UK firms with small and medium sized businesses (SMEs) making up most of the least productive 10%. SMEs adopting proven technologies and management practices has the potential to add £100bn to the UK’s gross value added (a measure of the value of goods and services produced).

The Business Basics Fund provides grants to test the most effective ways of encouraging SMEs to adopt such technology and management practices. The Fund is run as an open competition, crowdsourcing ideas from businesses, business support delivery bodies, academia, trade bodies and other parties.

References:

- Evaluation of the Transitional Arrangements Phase 1
- Evaluation of the Transitional Arrangements for Demand Side Response Phase 2
- Evaluation of the Transitional Arrangements for Demand Side Response Phase 3
- Business Basics Programme

# BEIS Monitoring and Evaluation Framework

Robust evaluation is a key element of the Business Basics Programme. The UK is taking a lead in applying experimental methods to boosting productivity in its evaluation of the Business Basics Programme. To ensure that all projects are evaluated properly and can be compared with other business support activities, an overarching Evaluation Framework has been developed.

The programme aim is to deliver randomised control trials testing the effectiveness of proposed approaches to increase adoption of basic technologies and management practices. The trials will assess whether there is a causal link between the approaches being tested and the desired outcomes. In the short-term they will measure behaviour change, intention to adopt, and where possible, adoption of identified technologies and management practices. Longer term impact evaluation can only take place in three to five years’ time to allow productivity impacts to emerge and be measurable. The appropriate data collection and data sharing agreements have been put in place to enable the longer-term learning from the programme.

With most of the projects still to complete it is too early to start answering the big policy questions set for the fund. However, valuable insights into programme delivery, experimental design, and qualitative evidence on what works to encourage adoption are already being gained, such as evidence that progress in the adoption process is not linear. These lessons have and will continue to be fed back to improve the delivery of the Programme.

The next Business Basics report will be produced upon completion of BBF1 projects.

# Quasi experimental evaluation

Quasi experimental design takes a similar approach to experimental design but lacks random assignment. Instead of a control group it identifies a comparison group that is as similar as possible to the treatment group in terms of baseline (pre-intervention) characteristics. The comparison group captures what would have been the outcomes if the intervention had not been implemented (i.e. the counterfactual). Quasi experimental evaluation methods typically used by BEIS include matching methods, duration modelling, interrupted time series, instrumental variables, synthetic control, and difference-in-difference.

Quasi-experimental case study: CRC Energy Efficiency Scheme (formerly Carbon Reduction Commitment)

The CRC was designed to drive energy efficiency and reduce carbon emissions in large non-intensive energy users, both public and private sector, across the UK. Collectively these are estimated to be responsible for around 10% of the UK’s greenhouse gas emissions.

The aim of the evaluation was to understand the actual impact of the CRC in driving action on energy use and to understand which elements of the policy have or have not worked and how this varied for different types of scheme participant.

The evaluation involved a quantitative survey, in-depth qualitative interviews and micro-econometric analysis, and these findings were drawn on for the synthesis report, along with:

- Business Support Evaluation Framework
- Business Basics Programme Progress Report October 2019
- Evaluation of the CRC Energy Efficiency Scheme

# BEIS Monitoring and Evaluation Framework

With desk research. To assess the impact of the CRC on energy use and carbon emissions, it was important to explore what would have happened in the absence of the CRC. Therefore, the micro-econometric analysis used difference-in-difference to assess the difference in energy consumption between CRC and non-CRC comparison groups. The qualitative and survey research also used non-CRC comparison groups to support the analysis and allow triangulation of evidence.

The evaluation found that while increasing energy costs were the single biggest driver for action on energy efficiency in recent years, there was evidence that the CRC had an impact on energy efficiency behavior and carbon emissions at least as sizeable as, if not greater than, the original impact assessment. Confidence in this conclusion was built because it was supported by all three research workstreams: micro-econometric, quantitative and qualitative.

Not all CRC participants were significantly influenced by the scheme: some were already taking early action on energy efficiency before the CRC. The quantitative and qualitative research found that the CRC was reported to have less impact (because of early action) on organizations which were:

1. relatively energy intensive
2. sensitive to reputation
3. sensitive to environmental factors
4. larger scale (in terms of capacity to address energy management)

The evaluation also found that the main drivers for energy efficiency action were raising awareness, especially at board level; the legal requirement for compliance; and through increasing the overall cost of energy. However, the influence of the CRC on reputation was less marked than its influence on finance or awareness.

Impact evaluation design in BEIS should be appropriate to the design of the policies being evaluated, the evaluation questions being asked, and the resources available. For example, an RCT may be the best method where interventions are relatively simple, and the outcome is easily measurable.

The role of qualitative research alongside experimental or quasi experimental methods While experimental and quasi experimental designs can derive estimates which robustly capture the causal effect of an intervention on its desired outcomes, they are to some extent ‘black-box’ in nature. They can attribute changes in outcomes to an intervention; often, however, these methods do not shed enough light on why or how the intervention had the reported impact.

Qualitative methods can offer insight on the process of the intervention and the experience of the participants, and comparison group, which is useful for project design (adapting the design for a different context with different participants, in a different location, or in a different manner) and improvement. For example, if a robust quasi experimental assessment found that a matched funded business training program had no positive impact, or a negative impact on turnover or employment for participants, qualitative research can help uncover why this was the case (e.g. participants may have felt wary about the quality of support they would receive, or that the funding they were required to contribute alongside the program funding was unaffordable). Similarly, if a positive impact is found, qualitative research can help to

# BEIS Monitoring and Evaluation Framework

Understand whether an intervention might have similar effects in future waves, based on contextual factors such as whether businesses want to grow, or have the expertise and investment required to do so.

BEIS requires qualitative research to be conducted alongside all experimental and quasi-experimental methodologies to learn why and how different groups were affected, to improve delivery and inform future policy design.

# Value for Money evaluation approaches used in BEIS

Value for Money evaluation aims to identify the value gained from resources used to implement an intervention.

BEIS tends to use cost-effectiveness or cost-benefit analysis (CBA). The first compares the costs of alternative ways of producing the same or similar outputs. The second quantifies in monetary terms as many of the costs and benefits of an intervention as feasible. CBA estimates whether the benefits of a project or policy outweigh its costs, and by how much relative to other alternatives – usually in comparison to what would have happened without the intervention.

# Value for money evaluation case study: Contracts for Difference (CfD)

The Contracts for Difference (CfD) scheme aims to give developers a higher level of confidence and certainty to invest in low carbon electricity generation, by agreeing to a fixed price for the sale of electricity over a 15-year contract.

The evaluation required a mix of impact, process, and economic evaluation. The evaluation is theory-based, adopting principles of realist approaches to address questions around how differences in context influence how developers respond to the scheme. It combines qualitative interviews with scheme participants and non-participants, with quantitative data collection and analysis. A modelled counterfactual was developed to conduct economic cost-benefit analysis to address questions around whether the scheme presents good value for money.

The publication of the evaluation and PIR are forthcoming.

|BEIS Monitoring and Evaluation Framework|A3. Theory of Change template|
|||
|Outcomes or Impacts or End Benefits|BEIS Strategic Objectives|
|Benefits|8|
|Intermediate Benefits|Secondary benefits|
|Main Tangible Output(s)| |
|Behaviour Change| |
|Barriers Overcome| |
|Capabilities Achieved| |
|Activities and Outputs|49|

|BEIS Monitoring and Evaluation Framework|Level of Mechanism|Level of Evidence|Strengths|Weaknesses|
||||||
|Lovel|Mechanism|Evidence|Lovel|Mechanism|Evidence|Strengths|Weaknesses|Evidence|Strengths|Weaknesses|
|Cayil|Mechanism|Evidence|Cuil|Mechanism|Evidence|Strengths|Weaknesses|Evidence|Strengths|Weaknesses|

BEIS Monitoring and Evaluation Framework
A4. Logical framework (logframe) template
51

# BEIS Monitoring and Evaluation Framework

As it says in the Magenta Book83 the collection of data required for an evaluation should be planned alongside the development of the intervention; where this does not occur, an evaluation may be impossible, severely limited or unnecessarily expensive.

In planning data collection, the following should be considered:

- the evaluation questions to be answered;
- who can provide the relevant data;
- data access constraints.

Planning activities should include:

- Identifying existing data from administrative and monitoring systems or larger-scale (long-term) surveys, to create a richer data set. This can enhance analysis, improve the quality of data, and avoid duplication of data collection. It combines different sets of data that have been collected for different purposes and can allow evaluators to answer complex questions in a cost-effective way. For this to be successful, accurate identifiers need to be collected to allow records to be paired. Unique identifiers can be straightforward to pair, in their absence careful thought needs to be given to the matching protocols.
- Identifying additional data requirements: considering whether accurate contact details for the individuals or organisations in the treatment and comparison or control groups (name, surname, landline number, mobile number, email address, etc.) are required in baseline and follow-up data collection or data linking; whether financial data relating to policy expenditure, or outcome related data will be required; and identifying who will collect it to ensure the appropriate systems are in place to do so, to the required standard, with the appropriate permissions for use.
- Data protection and security requirements: ensuring data protection requirements are considered in the intervention and evaluation design so data can be shared, used, and stored appropriately.
- Considering whether secondary data can be used to provide information about the wider context in which the policy is being delivered - e.g. national data on GDP, public attitudes, business performance, fuel use, prices, etc. - to help understand how external factors have affected outcomes, or monitor outcomes over time.

If you plan to conduct data linking (such as HMRC data, the Business Structure Database, Inter-Departmental Business Register (IDBR), or industry data and commercial datasets such as FAME (Forecasting Analysis and Modelling Environment)) to analyse impacts on longer-term turnover or employment, the minimum data required would be:

Companies House Registration Number (CRN)
Company Name and trading name if different
VAT Number
PAYE Number

83 https://www.gov.uk/government/publications/the-magenta-book

# BEIS Monitoring and Evaluation Framework

To track recipients of BEIS business support over time you would also want to:

- Unique Tax Reference Number
- Postcode

To track recipients of BEIS business support over time you would also want to:

- collect address, age of business, Sector (SIC) code, number of employees
- collect treatment and comparison or control baseline data before the intervention begins, so you can measure impact of the intervention on the treatment group (on turnover, Gross Value Added (GVA), labour productivity, for example)
- collect data in a timely manner to enable real-time feedback and improvement of the project delivery
- build in any data requirements from external organisations into contracting from the outset (such as format and frequency of reporting)
- ensure ethical and data protection requirements are considered prior to data collection

To track energy interventions over time to the National Energy Efficiency Data Framework84 or gas and electricity meter point data, you need to collect:

- the full address, including postcode of the properties you wish to match85
- the dates of the intervention so any potential effects can be identified.

For further information on data linking see section 4.6 in the Magenta Book86 and the how-to articles published as part of the data linking methods review87.

84 https://www.gov.uk/government/collections/national-energy-efficiency-data-need-framework

85 A scoping or feasibility study may help understanding of whether sufficient numbers of cases can be found in the data to undertake an impact evaluation. Low matching rates often indicate methods need to be adapted.

86 https://www.gov.uk/government/publications/the-magenta-book

87 https://www.gov.uk/government/publications/joined-up-data-in-government-the-future-of-data-linking-methods

# BEIS Monitoring and Evaluation Framework

# A6. Regulatory post implementation review plan template

|Part A: Basic Information|
||
|Measure and link to legislation:|e.g. Right to request flexible working|
|Policy description:|e.g. taken from IA|
|Policy objectives:|e.g. taken from IA|
|Net cost to business per year (£m)|Net Present Value (£million)|Total Cost (Present Value) (£million)|
|e.g. £xm taken directly from IA|e.g. £xm taken directly from IA|e.g. £xm taken directly from IA|
|Senior Responsible Officer:|e.g. SCS lead|
|Lead officials:|e.g. G7 working level leads (analyst and policy)|
|Statutory Review clause: Yes / No|Review Date: e.g. the deadline in legislation for statutory reviews|

# Part B: PIR Plan

Review objective:

- What is the objective of the review and what will it cover (e.g. the aim of the PIR is normally to assess the effectiveness of a regulation after it has been implemented and operational for a period of time. Will the PIR cover the whole regulation, recent amendments or parts of the regulation)?
- What are key milestones for the policy (using SMART targets) and when will you report against them?
- What factors are critical to success (what are the outputs / outputs as set out in the ‘Objectives’ section of the IA) and will this information be collected before, during and after implementation?

Baseline and Monitoring arrangements:

- Describe the counterfactual position against which the impact of the change will be measured
- Provide details on the data you are collecting, or expect to have available, that will feed into the post implementation review (e.g. what data sources will you be drawing on (surveying/sampling businesses, official statistics etc)?)
- Outline your monitoring targets and reporting plan

# BEIS Monitoring and Evaluation Framework

Review approach and rationale:

- Briefly describe your proposed methodology and planned interactions with stakeholders
- Please give your reasons for using this approach
- Expected intensity of the review (i.e. light-touch, impact evaluation, economic evaluation etc.). Page 15 of the PIR guidance will help inform this.
- Justification for intensity of the review
- Include details of the evaluation expert that has reviewed the design

# Part C: Internal Information:

Directorate / Partner organisation

Budget and resource for monitoring and evaluation

- If you have a budget, please give details and what it will be spent on (e.g. data collection, commissioning external research / evaluation).
- What resource do you intend to dedicate to data collection, analysis and review, over what timescales?

Legacy arrangements:

- Please provide details on your legacy arrangements to ensure evaluation can continue beyond the active phase of the policy – this often means having some resources devoted to evaluation even after the regulation has been implemented
- When will formal work on the PIR begin (remember that the PIR will need to go through internal, RPC & Cabinet Clearances).

# BEIS Monitoring and Evaluation Framework

56

This publication is available from: www.gov.uk/government/publications/beis-monitoring-and-
evaluation-framework


If you need a version of this document in a more accessible format, please email
enquiries@beis.gov.uk. Please tell us what format you need. It will help us if you say what
assistive technology you use.
